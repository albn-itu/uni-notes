# Introduction to Artificial Intelligence (KSINARI1KU)
Written by: Albert Rise Nielsen (19154)
Date of Birth: 17-07-2001
Date of Exam: 31-05-2024

## Problem 1
### a
See page 1 of the physical hand in

### b
On the root level we have 1 node. On the first level we have $n^2-n$ nodes. On the leaf level, with $n=3$ we also have $n^2-n$. 

If $d$ is the depth of the tree, where root is 0. Then the total number of nodes is $2^{d-1}\cdot(n^2-n)+1$.

This does not scale and only works for $n=2$ and $n=3$.

### c
$h(n)$ does not satisfy. The definition of a heuristic function is that it's the `estimated cost of the cheapest path from the state at node n to a goal state.` In this case while it accuratly predicts the cheapest path from the start state it becomes wronger the more wrong moves are made. Say we have `A` on the bottom with `C` on it. $h(n)$ would still be 2 despite the cheapest path being having to remove `C` then placing `B` on it, then place `A`, a cost of 3. It get's close due to the numbers being so small but it gets worse the bigger the numbers.

### d
Yes, $h(n)$ will always be under or equal to the cheapest path. See previous answer as to why.

### e
It will find a solution, it's just not guaranteed to find an optimal solution. A* will expand the path that appears to be on the cheapest path. In this case the heuristic is just really bad at showing what the cheapest path is, in the case that we are starting from a bad state, as all the neighbours of a really bad state could have the same heuristic value, this means A* might take longer to find the path than necessary. On the other hand if one started from the root state, there is a very clear path to the goal state, and A* would find it very quickly.

### g
See page 2 of the physical hand in

### h
Yes. The tree works quite well for this as it will only expand if it's unseen or has a lower cost. In this case the cost is moving a block so it won't get stuck in an infinite loop. It will eventually find a solution but for the fastest it requires a clause such as "the frontier have the same f -value, Greedy Best-First Search prefers first to expand a node, where block A is on the table if possible". This also indicates this may not be the best heuristic function for this problem.

## Problem 2
### a
Yes. Say that $AonC$ is true and $AonT$ is true, so that $A$ is in 2 places at once.

$$
\begin{align*}
KB \equiv (AonB &\Rightarrow\lnot AonC) \land \\
     (AonB &\Rightarrow\lnot AonT) \land \\
     (AonC &\Rightarrow\lnot AonB) \land \\
     (AonC &\Rightarrow\lnot AonT) \land \\
     (AonT &\Rightarrow\lnot AonB) \land \\
     (AonT &\Rightarrow\lnot AonC)
\end{align*}
$$

This would become
$$
\begin{align*}
KB \equiv (false &\Rightarrow false) \land \\
     (false &\Rightarrow false) \land \\
     (true &\Rightarrow true) \land \\
     (true &\Rightarrow false) \land \\
     (true &\Rightarrow true) \land \\
     (true &\Rightarrow false)
\end{align*}
$$

$$
\begin{align*}
KB \equiv (true) \land \\
     (true) \land \\
     (true) \land \\
     (false) \land \\
     (true) \land \\
     (true)
\end{align*}
$$

So the whole thing becomes $false$.

### b
First eliminate $a\Rightarrow b$ with $\lnot a \lor b$.
$$
\begin{align*}
KB \equiv (\lnot AonB &\lor\lnot AonC) \land \\
          (\lnot AonB &\lor\lnot AonT) \land \\
          (\lnot AonC &\lor\lnot AonB) \land \\
          (\lnot AonC &\lor\lnot AonT) \land \\
          (\lnot AonT &\lor\lnot AonB) \land \\
          (\lnot AonT &\lor\lnot AonC)
\end{align*}
$$

### c
This means that we want to prove that if $KB$ is true and A is on B then it follows that A is not on C and that A is not on the table.

In other words: In all worlds where KB is true and A is on B then A is not on C and A is not on the table.

### d
Assuming KB represents it's CNF, then the clause to prove unsatisfiable would be 
$$
\begin{align*}
    &(KB\land AonB)\land \lnot(\lnot AonC\land \lnot AonT)\\
    &\equiv (KB\land AonB)\land (\lnot\lnot AonC\lor \lnot\lnot AonT)\\
    &\equiv (KB\land AonB)\land (AonC\lor AonT)\\
\end{align*}
$$

So the CNF clause to prove unsatisfiable would be $(KB\land AonB)\land (AonC\lor AonT)$

### e
We need to show that the empty set $()$ can be derived from $AonB$, $AonC$ and $AonT$ and the set of clauses in $KB$.

Resolution on $AonB$ and $(\lnot AonB\lor\lnot AonT)$ gives us $(\lnot AonT)$.

Resolution on $AonC$ and $(\lnot AonC\lor\lnot AonT)$ gives us $(\lnot AonT)$.

Resolution on $AonT$ and $(\lnot AonT)$ gives us $()$, as required.

## Problem 3
### a

The definition of a deterministic action is whether the **outcome** is certain or uncertain.

The actions $N$ and $S$ are deterministic. They have a 100% certainty that the outcome is a bear or a wolf respectively.

$R$ is non deterministic (stochastic), as the outcome is uncertain, even though the action itself is certain.

### b
The Bellman equation. The Bellman equation is a recursive equation that decomposes the value function into two parts: the immediate reward and the discounted value of the successor state.

It looks like this:
$$
U(s) = \max_{a\in A(s)}\sum_{s'} P(s'|s, a)[R(s, a, s')) + \gamma U(s')]
$$

In this equation $P(s'|s, a)$ is the probability of reaching state $s'$ from state $s$ by taking action $a$, $R(s, a, s')$ is the reward of reaching state $s'$ from state $s$ by taking action $a$, $\gamma$ is the discount factor and $U(s')$ is the utility of state $s'$.

$\gamma$ has been defined as 0.9

For the root $I$ we calculate 
$$
    U(I)=\max_{a\in A(I)}\sum_{s'} P(s'|I, a)[R(I, a, s')) + \gamma U(s')]
$$

Moving from $I$ to $B$ and $W$ the probability of $P(s'|I, a)$ is 1, and the reward is 0.

Let's calculate $U(B)$. It has 2 final states ($s'$), survive or die. The probability of surviving is 0.7, and the reward is 1. The probability of dying is 0.3, and the reward is -1, there are not utilities here, and only 1 action, so we get

$$
\begin{align*}
    U(B)&=\sum_{s'} [P(s'|B, a)[R(B, a, s'))]\\
    &=P(1|B, R)R(B, R, 1) + P(-1|B, R)R(B, R, -1)\\
    &=0.7\cdot 1 + 0.3\cdot -1 = 0.4
\end{align*}
$$

$$
$$

Now we calculate $U(W)$. Same thing as before there is only one action, to run. But there are 3 outcomes, a 0.5 probability of going to $B$, a 0.35 probability of surviving and 0.15 probability of dying. In this case we have 2 outcomes as before, plus the outcome of the bear, so:

$$
\begin{align*}
    U(W)&=\sum_{s'} [P(s'|W, a)[R(W, a, s'))]\\
    U(W)&=P(1|W, R)R(W, R, 1) + P(-1|W, R)R(W, R, -1) + P(B|W, R)\gamma U(B)\\
    &=0.35\cdot 1 + 0.15\cdot -1 + 0.5\cdot 0.9 \cdot 0.4\\
    &= 0.38
\end{align*}
$$

Lastly we calculate $U(I)$, here we have 2 actions. Either $W$ or $B$ so:
$$
\begin{align*}
    U(I)&=\max_{a\in A(I)}\sum_{s'} P(s'|s, a)[R(s, a, s')) + \gamma U(s')]\\
    &=\max\begin{Bmatrix}
       \sum_{s'} P(s'|I, I\rightarrow B)[R(I, I\rightarrow B, s')) + \gamma U(s')]\\ 
       \sum_{s'} P(s'|I, I\rightarrow W)[R(I, I\rightarrow W, s')) + \gamma U(s')]\\ 
    \end{Bmatrix}\\
    &=\max\begin{Bmatrix}
       P(B|I, I\rightarrow B)[R(I, I\rightarrow B, B)) + \gamma U(B)]\\ 
       P(W|I, I\rightarrow W)[R(I, I\rightarrow W, W)) + \gamma U(W)]\\ 
    \end{Bmatrix}\\
    &=\max\begin{Bmatrix}
       P(B|I, I\rightarrow B)\gamma U(B)\\ 
       P(W|I, I\rightarrow W)\gamma U(W)\\ 
    \end{Bmatrix}\\
    &=\max\begin{Bmatrix}
       1\cdot 0.9 \cdot 0.4\\ 
       1\cdot 0.9 \cdot 0.38\\ 
    \end{Bmatrix}\\
    &=\max\begin{Bmatrix}
       0.36\\ 
       0.342
    \end{Bmatrix}\\
    &=0.36
\end{align*}
$$

### c
According to the results of the previous answer the best move would be to go to the bear in $B$, so take action $I \rightarrow B$. This action would have a utility of 0.36 while the utility of running into the wolf is $0.342$. Logically this makes sense as there is a 50% risk of having to deal with the bear in the case of the wolf, and even if you miss the bear, in case of the wolf, there is only a 35% chance of surviving the wolf. So just dealing with the bear that has a 70% chance of suriving is much better.

## Problem 4
### a
True. Basic variables follow the non-negativity constraint.

### b
There can be multiple optimal solutions, but not an infinite amount. For there to be an infinite amount the polyhedron would have to be unbounded, which would mean there is no optimal solution.

### c
True. If the polyhedron is unbounded then there is no optimal solution. If there is a corner point then it either has a feasible or optimal solution.

### d
False. The root of an expectiminimax tree is a max or min node, the first node thereafter is a chance node. It then usually alternates. So, assuming we start with a max node: max -> chance -> min then maybe chance or leaf etc.
